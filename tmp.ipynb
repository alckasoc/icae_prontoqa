{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96208622-d3ad-4f87-a7a7-b62e4a2ae2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-05 05:04:26.727671: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741151066.735954   28071 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741151066.739600   28071 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from training_utils import pretrain_tokenize_function\n",
    "from model import ICAE\n",
    "from train import ModelArguments, TrainingArguments\n",
    "\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    ")\n",
    "\n",
    "model_args = ModelArguments()\n",
    "training_args = TrainingArguments(output_dir=\"./output\")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=model_args.lora_r,\n",
    "    lora_alpha=model_args.lora_alpha,\n",
    "    lora_dropout=model_args.lora_dropout,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a5ee8e6-a1ae-4d17-89db-c6863db4e908",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed14d38fda464b7bbbd9fa0b3b1a5241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41058f7239dd43939ea75c1597876fcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "The new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7ac1d25a6c4847b6ccc4913a8fbe78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a598a84a5b0c41edb9433d89e7d41ec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c648f98817344110a6e66b2fc8a9d914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing the decoder...\n",
      "trainable params: 54542336 || all params: 16115105792 || trainable%: 0.33845471884569556\n",
      "Enabling gradient checkpointing...\n"
     ]
    }
   ],
   "source": [
    "model = ICAE(model_args, training_args, lora_config)\n",
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26575aa2-8ff7-4778-a985-554d6f8bb8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"345hop_random_true.json\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e9517cc-2056-42dc-93be-7e38c3129c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "processed_data = []\n",
    "\n",
    "for key, example in data.items():\n",
    "    for in_context_key, sample in example.items():\n",
    "        processed_data.append({\n",
    "            \"question\": sample[\"question\"],\n",
    "            \"query\": sample[\"query\"],\n",
    "            \"chain_of_thought\": \" \".join(sample[\"chain_of_thought\"]),\n",
    "            \"answer\": sample[\"answer\"]\n",
    "        })\n",
    "\n",
    "# Convert to a Hugging Face dataset\n",
    "hf_dataset = Dataset.from_list(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e14ff41c-b408-4b68-bf63-a02f2982e5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Each lepidopteran is an insect. Each arthropod is a protostome. Every animal is multicellular. Protostomes are invertebrates. Each whale is bony. Each painted lady is a butterfly. Invertebrates are animals. Butterflies are lepidopterans. Every insect is six-legged. Every insect is an arthropod. Arthropods are not bony. Sally is a painted lady.',\n",
       " 'query': 'True or false: Sally is not bony.',\n",
       " 'chain_of_thought': 'Sally is a painted lady. Each painted lady is a butterfly. Sally is a butterfly. Butterflies are lepidopterans. Sally is a lepidopteran. Each lepidopteran is an insect. Sally is an insect. Every insect is an arthropod. Sally is an arthropod. Arthropods are not bony. Sally is not bony.',\n",
       " 'answer': 'True'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c75d23b-ae98-47d3-8cdb-6f7f434098c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataset = hf_dataset.train_test_split(test_size=0.1)\n",
    "split_dataset = DatasetDict({\n",
    "    \"train\": split_dataset[\"train\"],\n",
    "    \"test\": split_dataset[\"test\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d4a372f-67b1-4835-bf07-87872a5d1a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'query', 'chain_of_thought', 'answer'],\n",
       "        num_rows: 4050\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'query', 'chain_of_thought', 'answer'],\n",
       "        num_rows: 450\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e4e4029-d2ae-4984-9fac-4d2a6bb03861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'query', 'chain_of_thought', 'answer'],\n",
       "    num_rows: 4050\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5a329bd-f062-4971-92d3-9988388e8ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_10_inference_examples.jsonl\", \"r\") as f:\n",
    "    train_10_inference_examples = [json.loads(line) for line in f]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "016cae9d-ab94-412b-88fa-5496e5a44fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Tabbies are cats. Vertebrates are chordates. Bilaterians are animals. Each chordate is a bilaterian. Each cat is a feline. Each carnivore is carnivorous. Snakes are cold-blooded. Mammals are vertebrates. Animals are not unicellular. Felines are carnivores. Each mammal is not cold-blooded. Each carnivore is a mammal. Stella is a tabby.',\n",
       " 'query': 'True or false: Stella is cold-blooded.',\n",
       " 'chain_of_thought': 'Stella is a tabby. Tabbies are cats. Stella is a cat. Each cat is a feline. Stella is a feline. Felines are carnivores. Stella is a carnivore. Each carnivore is a mammal. Stella is a mammal. Each mammal is not cold-blooded. Stella is not cold-blooded.',\n",
       " 'answer': 'False'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_10_inference_examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01d6e945-4055-4a04-8f44-a0727ad65ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ba3ce73c5b47b9b568427b14fb8aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4050 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14ee244679664caa8086a182c3c6bc46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/450 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from train import preprocess_function\n",
    "import json\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "with open(\"345hop_random_true.json\") as f:\n",
    "    data = json.load(f)\n",
    "processed_data = []\n",
    "\n",
    "for key, example in data.items():\n",
    "    for in_context_key, sample in example.items():\n",
    "        processed_data.append({\n",
    "            \"question\": sample[\"question\"],\n",
    "            \"query\": sample[\"query\"],\n",
    "            \"chain_of_thought\": \" \".join(sample[\"chain_of_thought\"]),\n",
    "            \"answer\": sample[\"answer\"]\n",
    "        })\n",
    "\n",
    "hf_dataset = Dataset.from_list(processed_data)\n",
    "split_dataset = hf_dataset.train_test_split(test_size=0.1)\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "eval_dataset = split_dataset[\"test\"]\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess_function)\n",
    "eval_dataset = eval_dataset.map(preprocess_function)\n",
    "\n",
    "train_dataset = train_dataset.shuffle(seed=42)\n",
    "eval_dataset = eval_dataset.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d3406d2-0566-468f-9240-fcddd33cd05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "259f9c9679d840ff91f7427e76d1deae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3dd4807cf0f4695b546462de2d8777a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "The new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing the decoder...\n",
      "trainable params: 436224000 || all params: 16496787456 || trainable%: 2.6442966617803045\n",
      "Enabling gradient checkpointing...\n"
     ]
    }
   ],
   "source": [
    "from train import ModelArguments, TrainingArguments\n",
    "from model import ICAE\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    ")\n",
    "lora_config = LoraConfig(\n",
    "    r=1024,\n",
    "    lora_alpha=256,\n",
    "    lora_dropout=0,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model_args = ModelArguments()\n",
    "model_args.model_name_or_path = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "training_args = TrainingArguments(\"./output\")\n",
    "model = ICAE(model_args, training_args, lora_config).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f2e251-0207-41ec-9305-f18915a8812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(pretrain_tokenize_function, batched=True, batch_size=1, fn_kwargs={\"model\": model, \"mem\": MEM_TOKENS, \"input_type\": args.input_type, \"lm_ratio\": training_args.lm_ratio})\n",
    "eval_dataset = eval_dataset.map(pretrain_tokenize_function, batched=True, fn_kwargs={\"model\": model, \"mem\": MEM_TOKENS, \"input_type\": args.input_type})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ccccac-ecb9-4239-b405-cbd6387337a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
